{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893c0661-1146-4c6a-a283-cfb2bb9b9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import sqlalchemy as db\n",
    "import mysql.connector\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"hockey\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n",
    "\n",
    "df = pd.read_csv(\"sportTweets.csv\")\n",
    "\n",
    "# specify database configurations\n",
    "db_connection = mysql.connector.connect(host = 'database',\n",
    "                                        port = 3306, \n",
    "                                        user = 'symfony', \n",
    "                                        passwd = 'symfony', \n",
    "                                        db = 'symfony_docker')\n",
    "\n",
    "# create and use a new database\n",
    "db_cursor = db_connection.cursor()\n",
    "db_cursor.execute(\"USE symfony_docker;\")\n",
    "\n",
    "#db_cursor.execute(\"CREATE TABLE Statistics(year YEAR, count INT);\")\n",
    "\n",
    "\n",
    "\n",
    "sparkDF = spark.createDataFrame(df)\n",
    "tweets_2021 = sparkDF.filter(sparkDF['Date'] >= '2021-01-01')\n",
    "tweets_2020 = sparkDF.filter((sparkDF['Date']>='2020-01-01') & (sparkDF['Date']<='2020-12-31'))\n",
    "tweets_2019 = sparkDF.filter((sparkDF['Date']>='2019-01-01') & (sparkDF['Date']<='2019-12-31'))\n",
    "\n",
    "num_of_hockey_tweets_2021 = tweets_2021.selectExpr(\"lower(Tweet) as lower\")\\\n",
    ".withColumn(\"cleaned\", f.regexp_replace(f.col(\"lower\"),\"[^a-z |*]\", \" \"))\\\n",
    ".filter(col(\"cleaned\").contains(\"hockey\"))\\\n",
    ".count()\n",
    "num_of_hockey_tweets_2020 = tweets_2020.selectExpr(\"lower(Tweet) as lower\")\\\n",
    ".withColumn(\"cleaned\", f.regexp_replace(f.col(\"lower\"),\"[^a-z |*]\", \" \"))\\\n",
    ".filter(col(\"cleaned\").contains(\"hockey\"))\\\n",
    ".count()\n",
    "num_of_hockey_tweets_2019 = tweets_2019.selectExpr(\"lower(Tweet) as lower\")\\\n",
    ".withColumn(\"cleaned\", f.regexp_replace(f.col(\"lower\"),\"[^a-z |*]\", \" \"))\\\n",
    ".filter(col(\"cleaned\").contains(\"hockey\"))\\\n",
    ".count()\n",
    "\n",
    "columns = ['Period', 'Count']\n",
    "data = [('2019', num_of_hockey_tweets_2019),('2020', num_of_hockey_tweets_2020),('2021', num_of_hockey_tweets_2021)]\n",
    "\n",
    "sql = \"INSERT INTO Statistics(year,count) VALUES(%s, %s)\"\n",
    "# Create a new record\n",
    "db_cursor.executemany(sql,data)\n",
    "\n",
    "# connection is not autocommit by default. So we must commit to save our changes.\n",
    "db_connection.commit()\n",
    "\n",
    "#rdd = spark.createDataFrame(data).toDF(*columns)\n",
    "#rdd.toPandas().to_csv('numOfHockeyTweets19-21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fe26f1-a06a-43fa-af73-23b2f3770547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymysql\n",
      "Successfully installed pymysql-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf92107-87e8-4f44-be70-9a0b47a0fa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp39-cp39-manylinux1_x86_64.whl (363 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.6/363.6 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.9/site-packages (from wordcloud) (9.1.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /opt/conda/lib/python3.9/site-packages (from wordcloud) (1.21.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.33.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.0.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc885082-5678-431a-8893-991550946492",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1513458334.py, line 43)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [22]\u001b[0;36m\u001b[0m\n\u001b[0;31m    .generate(' '.join(wordsHockeyTweets['words']))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#% matplotlib inline\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\"hockey\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n",
    "\n",
    "df = pd.read_csv(\"sportTweets.csv\")\n",
    "\n",
    "sparkDF = spark.createDataFrame(df)\n",
    "wordsHockeyTweets = sparkDF.selectExpr(\"lower(Tweet) as lowerTweets\")\\\n",
    ".withColumn(\"cleaned\", f.regexp_replace(f.col(\"lowerTweets\"), \"[^a-z |*]\", \"  \"))\\\n",
    ".filter(col(\"cleaned\").contains(\"hockey\"))\\\n",
    ".select(\"*\", f.expr(\"split(cleaned, ' ') splitted\"))\\\n",
    ".select(f.explode(f.col(\"splitted\")).alias(\"words\"))\\\n",
    ".where(\"length(words)>4\")\\\n",
    ".groupBy(\"words\").count()\\\n",
    ".orderBy(f.desc(\"count\")).limit(50)\n",
    "wordsHockeyTweets.show()\n",
    "\n",
    "\n",
    "#Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"https\"])\n",
    "\n",
    "text = \" \".join(word for word in wordsHockeyTweets.words)\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(' '.join(wordsHockeyTweets['words']))\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ebac7-8749-4eac-a32e-108c6663ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12109a95-51e4-49e0-847e-5114d734b78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
